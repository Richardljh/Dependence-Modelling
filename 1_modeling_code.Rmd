---
title: "Joint modelling for dependent frequency and severity"
author: "Jiahong Li and Guangyuan Gao"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

The ausprivauto0405 dataset is based on one-year vehicle insurance policies taken out in 2004 or 2005. There are 67856 policies, of which 4624 had at least one claim.

```{r data-check}
source("0_process.R")
source("0_functions.R")
dim(dat1)

emp_fre<-sum(dat1$ClaimNb)/sum(dat1$Exposure) # empirical claims frequency
hist(dat1$Exposure)
dpois(0,emp_fre)+dpois(1,emp_fre)+dpois(2,emp_fre) # very low chance to make more than 2 claims

unique(dat2$ClaimNb)
dim(dat2)
sum(dat1$ClaimNb>0)

dim(dat1_mat)
```

 
# Marginal modeling 

##  Frequency models

### Poisson regression

```{r}
names(dat1)
ind_test<-5
sum(dat1$ind==ind_test)
names(dat1_mat)

# poi_reg <- glm(ClaimNb ~ LnVehValue + VehAgeoldest + VehAgeyoung + VehAgeyoungest + VehBodyCaravan + VehBodyCoupe + VehBodyHardtop + VehBodyHatchback + VehBodyMinibus + VehBodyOthers + VehBodyTruck + VehBodyUtility + VehBodyVan + VehBodyWagon + GenderMale + DrivAgeold + DrivAgeoldest + DrivAgeworking + DrivAgeyoung + DrivAgeyoungest + offset(log(Exposure)) , data = dat1_mat[dat1_mat$ind!=ind_test,], family = poisson(link = "log"))
poi_reg <- glm(ClaimNb ~ LnVehValue + VehAge + VehBody + Gender + DrivAge +  offset(log(Exposure)) , data = dat1[dat1$ind!=ind_test,], family = poisson(link = "log"))
poi_reg<-step(poi_reg,trace = 0)
options(digits=5)
summary(poi_reg,digits=5)

dat1$PoiNb<-predict(poi_reg,newdata = dat1,type = "response")
dat2$PoiNb<-predict(poi_reg, newdata = dat2,type = "response")
homo_freq<-sum(dat1$ClaimNb[dat1$ind!=ind_test])/sum(dat1$Exposure[dat1$ind!=ind_test])
dat1$HomoNb<-dat1$Exposure*homo_freq

Poisson.Deviance(dat1$PoiNb[dat1$ind==ind_test], dat1$ClaimNb[dat1$ind==ind_test])
Poisson.Deviance(dat1$HomoNb[dat1$ind==ind_test], dat1$ClaimNb[dat1$ind==ind_test])
```

Poisson Regression is better based on Poisson Deviance Loss on test_feq and minus ZTP loglikelihood on test_sev. Due to the predictive performance of Poisson regression, we think three part model proposed by Shi (2015) is not appropriate for these data.

```{r}
nb_reg <- glm.nb(ClaimNb ~ LnVehValue + VehAge + VehBody + Gender + DrivAge +  offset(log(Exposure)) , data = dat1[dat1$ind!=ind_test,], link= log)
nb_reg<-step(nb_reg,trace = 0)
options(digits=5)
summary(nb_reg,digits=5)

dat1$NBNb<-predict(nb_reg,newdata = dat1, type = "response")
dat2$NBNb<-predict(nb_reg, newdata = dat2, type = "response")
```





```{r}
mx_reg <- gamlssMX(ClaimNb ~ LnVehValue  + DrivAge +  offset(log(Exposure)) , data = dat1[dat1$ind!=ind_test,],family = 'PO', K=2, control = MX.control(seed = 1010))
mx_reg
```

```{r}
mx_reg_1 <- mx_reg$models[[1]]
mx_reg_2 <- mx_reg$models[[2]]
dat1$MXNb_1 <- exp(model.matrix(ClaimNb ~ LnVehValue  + DrivAge +  log(Exposure), data = dat1)%*%c(mx_reg_1$mu.coefficients,1))
dat1$MXNb_2 <- exp(model.matrix(ClaimNb ~ LnVehValue  + DrivAge +  log(Exposure), data = dat1)%*%c(mx_reg_2$mu.coefficients,1))
dat1$MXNb <- mx_reg$prob[1]*dat1$MXNb_1 + mx_reg$prob[2]*dat1$MXNb_2
dat2$MXNb_1 <- exp(model.matrix(ClaimNb ~ LnVehValue  + DrivAge +  log(Exposure), data = dat2)%*%c(mx_reg_1$mu.coefficients,1))
dat2$MXNb_2 <- exp(model.matrix(ClaimNb ~ LnVehValue  + DrivAge +  log(Exposure), data = dat2)%*%c(mx_reg_2$mu.coefficients,1))
dat2$MXNb <- mx_reg$prob[1]*dat2$MXNb_1 + mx_reg$prob[2]*dat2$MXNb_2
```



##  Severity models

### Without claim counts

```{r}
fit_gamma<-fitdist(dat2$ClaimSev,"gamma",method="mme")
plot(fit_gamma)
fit_lnorm<-fitdist(dat2$ClaimSev,"lnorm",method="mme")
plot(fit_lnorm)
gofstat(list(fit_gamma,fit_lnorm))

# ga_reg <- glm(ClaimSev ~ LnVehValue + VehAgeoldest + VehAgeyoung + VehAgeyoungest + VehBodyCaravan + VehBodyCoupe + VehBodyHardtop + VehBodyHatchback + VehBodyMinibus + VehBodyOthers + VehBodyTruck + VehBodyUtility + VehBodyVan + VehBodyWagon + GenderMale + DrivAgeold + DrivAgeoldest + DrivAgeworking + DrivAgeyoung + DrivAgeyoungest + Exposure, data = dat2_mat[dat2_mat$ind!=ind_test,], family = Gamma(link="log"), weights=ClaimNb)
ga_reg <- glm(ClaimSev ~ LnVehValue + VehAge + VehBody + Gender + DrivAge + Exposure, data = dat2[dat2$ind!=ind_test,], family = Gamma(link="log"), weights=ClaimNb)
ga_reg<-step(ga_reg,trace=0)
# ln_reg <- glm(LnSev ~ LnVehValue + VehAgeoldest + VehAgeyoung + VehAgeyoungest + VehBodyCaravan + VehBodyCoupe + VehBodyHardtop + VehBodyHatchback + VehBodyMinibus + VehBodyOthers + VehBodyTruck + VehBodyUtility + VehBodyVan + VehBodyWagon + GenderMale + DrivAgeold + DrivAgeoldest + DrivAgeworking + DrivAgeyoung + DrivAgeyoungest + Exposure, data = dat2_mat[dat2_mat$ind!=ind_test,], family = gaussian(link="identity"))
ln_reg <- glm(LnSev ~ LnVehValue + VehAge + VehBody + Gender + DrivAge + Exposure, data = dat2[dat2$ind!=ind_test,], family = gaussian(link="identity"))
ln_reg<-step(ln_reg,trace = 0)
summary(ga_reg)
summary(ln_reg)

# pdf("./plots/gamma_qq.pdf")
qqnorm(residuals(ga_reg),main="Q-Q plot for Gamma severity model")
qqline(residuals(ga_reg),lty=2)
# dev.off()

# pdf("./plots/ln_qq.pdf")
qqnorm(residuals(ln_reg),main="Q-Q plot for log-normal severity model")
qqline(residuals(ln_reg),lty=2)
# dev.off()

par(mfrow=c(2,2))
plot(ga_reg)
plot(ln_reg)

dat2$GaSe <- predict(ga_reg,newdata = dat2, type = 'response')
dat1$GaSe <- predict(ga_reg,newdata = dat1, type = 'response')

dat2$LnSe <- predict(ln_reg,newdata = dat2, type = 'response')
dat1$LnSe <- predict(ln_reg,newdata = dat1, type = 'response')
```

### With claim counts (gamma negative relationship; log-normal positive)

```{r}
#ga_reg_n <- glm(ClaimSev ~ LnVehValue + VehAgeoldest + VehAgeyoung + VehAgeyoungest + VehBodyCaravan + VehBodyCoupe + VehBodyHardtop + VehBodyHatchback + VehBodyMinibus + VehBodyOthers + VehBodyTruck + VehBodyUtility + VehBodyVan + VehBodyWagon + GenderMale + DrivAgeold + DrivAgeoldest + DrivAgeworking + DrivAgeyoung + DrivAgeyoungest + Exposure + ClaimNb, data = dat2_mat[dat2_mat$ind!=ind_test,],  family = Gamma(link="log"), weights = ClaimNb)
ga_reg_n <- glm(ClaimSev ~ LnVehValue + VehAge + VehBody + Gender + DrivAge +  ClaimNb, data = dat2[dat2$ind!=ind_test,], family = Gamma(link="log"), weights=ClaimNb)
ga_reg_n<-step(ga_reg_n,trace=0)
#ln_reg_n <- glm(LnSev ~ LnVehValue + VehAgeoldest + VehAgeyoung + VehAgeyoungest + VehBodyCaravan + VehBodyCoupe + VehBodyHardtop + VehBodyHatchback + VehBodyMinibus + VehBodyOthers + VehBodyTruck + VehBodyUtility + VehBodyVan + VehBodyWagon + GenderMale + DrivAgeold + DrivAgeoldest + DrivAgeworking + DrivAgeyoung + DrivAgeyoungest + Exposure + ClaimNb, data = dat2_mat[dat2_mat$ind!=ind_test,],  family = gaussian(link="identity"))
ln_reg_n <- glm(LnSev ~ LnVehValue + VehAge + VehBody + Gender + DrivAge +  ClaimNb, data = dat2[dat2$ind!=ind_test,], family = gaussian(link="identity"))
ln_reg_n<-step(ln_reg_n,trace=0)

summary(ga_reg_n)
summary(ln_reg_n)
par(mfrow=c(2,2))
plot(ga_reg_n)
plot(ln_reg_n)

dat2$GaSe_N <- predict(ga_reg_n, newdata = dat2, type = 'response')
dat1$GaSe_N <- predict(ga_reg_n, newdata = dat1, type = 'response') 

dat2$LnSe_N <- predict(ln_reg_n, newdata = dat2, type = 'response')
dat1$LnSe_N <- predict(ln_reg_n, newdata = dat1, type = 'response')
```

### Comparison of severity models

```{r}
Gamma.Deviance(dat2$GaSe[dat2$ind==ind_test],dat2$ClaimSev[dat2$ind==ind_test],dat2$ClaimNb[dat2$ind==ind_test])
Gamma.Deviance(dat2$GaSe_N[dat2$ind==ind_test], dat2$ClaimSev[dat2$ind==ind_test],dat2$ClaimNb[dat2$ind==ind_test])

mean((dat2$LnSe[dat2$ind==ind_test]-dat2$LnSev[dat2$ind==ind_test])^2)
mean((dat2$LnSe_N[dat2$ind==ind_test]-dat2$LnSev[dat2$ind==ind_test])^2)
```

# Joint modelling 

## Estimation of $\rho$ by IFM
```{r}
z1m<-function(lambda_1, lambda_2, pi_1, pi_2){
  FT_1 <- (1-dpois(0,lambda_1)-dpois(1,lambda_1))/(1-dpois(0,lambda_1))
  FT_2 <- (1-dpois(0,lambda_2)-dpois(1,lambda_2))/(1-dpois(0,lambda_2))
  return(qnorm(pi_1*FT_1+pi_2*FT_2))
}
```

```{r}
dat2$z_fre<-z1(dat2$PoiNb)
dat2$z_sev<-z2(summary(ga_reg)$dispersion, dat2$GaSe, dat2$ClaimSev, dat2$ClaimNb)
dat2$z_sev_ln<- z2_ln(summary(ln_reg)$dispersion, ln_mu=dat2$LnSe, ln_sev=dat2$LnSev)
dat2$z_fre_m<-z1m(dat2$MXNb_1, dat2$MXNb_2, mx_reg$prob[1], mx_reg$prob[2])
dat2_learn<-dat2[dat2$ind!=ind_test,]
dat1_test<-dat1[dat1$ind==ind_test,]

obj_fun<-function(rho){
  rho_f(ind=ifelse(dat2_learn$ClaimNb==1,1,0), z1=dat2_learn$z_fre,z2=dat2_learn$z_sev,rho)
}
obj_fun_ln<-function(rho){
  rho_f(ind=ifelse(dat2_learn$ClaimNb==1,1,0), z1=dat2_learn$z_fre,z2=dat2_learn$z_sev_ln,rho)
}
(rho_hat = optim(par=0, obj_fun, method='Brent', lower=-1, upper =1)$par)
(rho_hat_ln = optim(par=0, obj_fun_ln, method='Brent', lower=-1, upper =1)$par)
coef(ga_reg_n)[length(coef(ga_reg_n))]
coef(ln_reg_n)[length(coef(ln_reg_n))]
TT = 2000
```

```{r}
library(pracma)
fisher_infor<-fderiv(obj_fun_ln,rho_hat_ln, n=2, method = "central")
(rho_hat_sd <- sqrt(1/fisher_infor))
c(rho_hat_ln-qnorm(0.975)*rho_hat_sd,rho_hat_ln+qnorm(0.975)*rho_hat_sd)
```
```{r}
obj_fun_ln_m<-function(rho){
  rho_f(ind=ifelse(dat2_learn$ClaimNb==1,1,0), z1=dat2_learn$z_fre_m, z2=dat2_learn$z_sev_ln, rho)
}
(rho_hat_ln_m = optim(par=0, obj_fun_ln_m, method='Brent', lower=-1, upper=1)$par)
```

## Conditional expectation of logged severity given N

```{r}
lambda_range<-range(dat1$PoiNb)
lambda_range<-seq(lambda_range[1],lambda_range[2],by=0.01)
uu<-(1-dpois(0,lambda_range)-dpois(1,lambda_range))/(1-dpois(0,lambda_range))
diff_sev1<-function(u,rho,sigma){
  rho*sigma/(1-u)*dnorm(qnorm(u))
}

diff_sev2<-function(u,rho,sigma){
  -rho*sigma/(u)*dnorm(qnorm(u))
}

m1<-diff_sev1(uu,rho_hat_ln,sqrt(summary(ln_reg)$dispersion))+mean(dat2$LnSe)
m2<-diff_sev2(uu,rho_hat_ln,sqrt(summary(ln_reg)$dispersion))+mean(dat2$LnSe)

# pdf("./plots/copula_Y.pdf")
plot(lambda_range,m1,type="l",ylim=c(6.6,7.0),xlab="claims frequency",ylab="conditional expection of logged severity",lty=2)
lines(lambda_range,m2,type="l",lty=1)
abline(h=mean(dat2$LnSev),lty=3)
legend("topright",c("given N*=2+","given N*=1", "empirical mean of logged severity"),lty=c(1,2,3))
# dev.off()

# pdf("./plots/copula_diff.pdf")
plot(lambda_range,m2-m1,type="l",xlab="claims frequency",ylab="difference in conditional expectation",lty=1,lwd=1.2)
# dev.off()

mm1<-rep(mean(dat2$LnSe_N)+1* coef(ln_reg_n)[length(coef(ln_reg_n))],length(lambda_range))
mm2<-rep(mean(dat2$LnSe_N)+2* coef(ln_reg_n)[length(coef(ln_reg_n))],length(lambda_range))


```

## Simulation based predictive distributions

### Independent method

```{r}
xlim0<-c(400,900)
breaks0<-seq(400,900,10)
ylim0<-c(0,200)

names(dat1)
actualtotalloss <- sum(dat1$ClaimAmount[dat1$ind==ind_test])
set.seed(1010)

independent_S = matrix(nrow = nrow(dat1_test), ncol = TT)
independent_S_ln = matrix(nrow = nrow(dat1_test), ncol = TT)

for(i in 1:nrow(dat1_test)){
  independent_S[i,] <- pred_condition_S(lambda = dat1_test$PoiNb[i], mu = dat1_test$GaSe[i], phi = (summary(ga_reg))$dispersion, coef_N = 0, TT = TT, dis="gamma")
    if (i%%1000==0){print(i)}
}
independenttotalloss <- apply(independent_S, 2, sum)

for(i in 1:nrow(dat1_test)){
  independent_S_ln[i,] <- pred_condition_S(lambda = dat1_test$PoiNb[i], mu = dat1_test$LnSe[i], phi = (summary(ln_reg))$dispersion, coef_N = 0, TT = TT, dis="lnorm")
    if (i%%1000==0){print(i)}
}
independenttotalloss_ln <- apply(independent_S_ln, 2, sum)

hist(independenttotalloss,  xaxt="n", xlab = 'independent total loss', main = '')
abline(v=actualtotalloss,lwd=4,col="blue")
ecdfindependent <- ecdf(independenttotalloss)
ecdfindependent(actualtotalloss)
(mean(independenttotalloss)-actualtotalloss)/actualtotalloss
ind_percent<-agg_per(simulated = independent_S, actual = dat1_test$ClaimAmount)
hist(ind_percent)

# pdf("./plots/ind_pred.pdf")
hist(independenttotalloss_ln/1000, xlab = 'predicted total claims amount (in thousands) in the test data', main = 'independent modelling',ylab="frequency",xlim = xlim0,breaks=breaks0,ylim = ylim0)
abline(v=actualtotalloss/1000,lwd=3,col=1)
legend("topright",c("actual total claims amount"),lty=1,lwd=3)
box()
# dev.off()

ecdfindependent_ln <- ecdf(independenttotalloss_ln)
ecdfindependent_ln(actualtotalloss)
(mean(independenttotalloss_ln)-actualtotalloss)/actualtotalloss
ind_percent_ln<-agg_per(simulated = independent_S_ln, actual = dat1_test$ClaimAmount)
hist(ind_percent_ln)

da<-data.frame(actual=dat1$ClaimAmount[dat1$ind==ind_test])
da$ind_gamma<-apply(independent_S,1,mean)
da$ind_ln<-apply(independent_S_ln,1,mean)

gini(loss="actual",score=c("ind_gamma","ind_ln"),data=da)
```

### Conditional approach from Garrido et al. (2016)

```{r}
set.seed(1010)

# summary(ga_reg_n)
coef_N<- coef(ga_reg_n)[length(coef(ga_reg_n))]
dat1_test$GaSe_NN<-dat1_test$GaSe_N/exp(dat1_test$ClaimNb*coef_N)

# summary(ln_reg_n)
coef_N_ln<- coef(ln_reg_n)[length(coef(ln_reg_n))]
dat1_test$LnSe_NN<-dat1_test$LnSe_N- dat1_test$ClaimNb*coef_N_ln

condition_S = matrix(nrow = nrow(dat1_test), ncol = TT)
condition_S_ln = matrix(nrow = nrow(dat1_test), ncol = TT)

for(i in 1:nrow(dat1_test)){
  condition_S[i,] <- pred_condition_S(lambda = dat1_test$PoiNb[i], mu = dat1_test$GaSe_NN[i], phi = (summary(ga_reg_n))$dispersion, coef_N=coef_N, TT = TT, dis="gamma")
  if (i%%1000==0){print(i)}
}
conditiontotalloss <- apply(condition_S, 2, sum)

for(i in 1:nrow(dat1_test)){
  condition_S_ln[i,] <- pred_condition_S(lambda = dat1_test$PoiNb[i], mu = dat1_test$LnSe_NN[i], phi = summary(ln_reg_n)$dispersion, coef_N=coef_N_ln, TT = TT, dis="lnorm")
  if (i%%1000==0){print(i)}
}
conditiontotalloss_ln <- apply(condition_S_ln, 2, sum)

hist(conditiontotalloss, xaxt="n", xlab = 'total loss of conditional model', main = '')
abline(v=actualtotalloss,lwd=4,col="blue")
ecdfcondition <- ecdf(conditiontotalloss)
ecdfcondition(actualtotalloss)
(mean(conditiontotalloss)-actualtotalloss)/actualtotalloss
condi_percent<-agg_per(simulated = condition_S, actual = dat1_test$ClaimAmount)
hist(condi_percent)

hist(conditiontotalloss_ln, xaxt="n", xlab = 'total loss of conditional model', main = '')
abline(v=actualtotalloss,lwd=4,col="blue")
ecdfcondition_ln <- ecdf(conditiontotalloss_ln)
ecdfcondition_ln(actualtotalloss)
(mean(conditiontotalloss_ln)-actualtotalloss)/actualtotalloss
condi_percent_ln<-agg_per(simulated = condition_S_ln, actual = dat1_test$ClaimAmount)
hist(condi_percent_ln)

da$cond_gamma<-apply(condition_S,1,mean)
da$cond_ln<-apply(condition_S_ln,1,mean)

gini(loss="actual",score=c("ind_gamma","cond_gamma","ind_ln","cond_ln"),data=da)
gini(loss="actual",score=c("ind_ln","cond_ln"),data=da)
```

### Our predictive distributions 

```{r}
set.seed(1010)
our_S = matrix(nrow = sum(dat1$ind==ind_test), ncol = TT)
our_S_ln = matrix(nrow = sum(dat1$ind==ind_test), ncol = TT)

for(i in 1:nrow(dat1_test)){
  our_S[i,] <- pred_S(lambda = dat1_test$PoiNb[i], mu = dat1_test$GaSe[i], phi = (summary(ga_reg))$dispersion, rho_hat=rho_hat, TT = TT, dis="gamma")
  if (i%%1000==0){print(i)}
}

for(i in 1:nrow(dat1_test)){
  our_S_ln[i,] <- pred_S(lambda = dat1_test$PoiNb[i], mu = dat1_test$LnSe[i], phi = (summary(ln_reg))$dispersion, rho_hat=rho_hat_ln, TT = TT, dis="lnorm")
  if (i%%1000==0){print(i)}
}
ourtotalloss <- apply(our_S, 2, sum)
ourtotalloss_ln <- apply(our_S_ln, 2, sum)

hist(ourtotalloss, xaxt="n", xlab = 'total loss of our copula model', main = '')
abline(v=actualtotalloss,lwd=4,col="blue")
ecdfour <- ecdf(ourtotalloss)
ecdfour(actualtotalloss)
(mean(ourtotalloss)-actualtotalloss)/actualtotalloss
our_percent<-agg_per(simulated = our_S, actual = dat1_test$ClaimAmount)
hist(our_percent)

# pdf("./plots/our_pred.pdf")
hist(ourtotalloss_ln/1000, xlab = 'predicted total claims amount (in thousands) in the test data', main = 'our proposed copula model',ylab="frequency",xlim = xlim0,breaks=breaks0,ylim=ylim0)
abline(v=actualtotalloss/1000,lwd=3,col=1)
legend("topright",c("actual total claims amount"),lty=1,lwd=3)
box()
# dev.off()

ecdfour_ln <- ecdf(ourtotalloss_ln)
ecdfour_ln(actualtotalloss)
(mean(ourtotalloss_ln)-actualtotalloss)/actualtotalloss
our_percent_ln<-agg_per(simulated = our_S_ln, actual = dat1_test$ClaimAmount)
hist(our_percent_ln)

da$our_gamma<-apply(our_S,1,mean)
da$our_ln<-apply(our_S_ln,1,mean)

gini(loss="actual",score=c("ind_ln","cond_ln","our_ln"),data=da)
```

```{r}
pdf("./plots/our_pred.pdf")
hist(ourtotalloss_ln/1000, xlab = 'predicted total claims amount (in thousands) in the test data', main = 'our proposed copula model',ylab="frequency",xlim = xlim0,breaks=breaks0,ylim=ylim0)
abline(v=actualtotalloss/1000,lwd=3,col=1)
abline(v=quantile(ourtotalloss_ln/1000,0.75),lty=2,lwd=3,col=1)
abline(v=quantile(ourtotalloss_ln/1000,0.95),lty=3,lwd=3,col=1)
legend("topright",c("actual total claims amount",
                    "75% VaR of predictions",
                    "95% VaR of predictions"),lty=c(1,2,3),lwd=3)
box()
dev.off()
```

### Copula approach of Kramer (2013) 

estimation of $\rho$ by IFM

```{r}
(kramer_rho <-ifm_rho_kramer(
  ClaimNb = dat2_learn$ClaimNb,
  lambda = dat2_learn$PoiNb,
  Sev = dat2_learn$ClaimSev,
  mu = dat2_learn$GaSe, # mean of gamma distribution
  phi = (summary(ga_reg))$dispersion, # dispersion parameter of gamma distribution
  ln=F))
(kramer_rho_ln <-ifm_rho_kramer(
  ClaimNb = dat2_learn$ClaimNb,
  lambda = dat2_learn$PoiNb,
  Sev = dat2_learn$LnSev,
  mu = dat2_learn$LnSe, # mean of gamma distribution
  phi = (summary(ln_reg))$dispersion, # dispersion parameter of gamma distribution
  ln=T))
```



```{r}
set.seed(1010)
kramer_S = matrix(nrow = nrow(dat1_test), ncol = TT)
kramer_S_ln = matrix(nrow = nrow(dat1_test), ncol = TT)

for(i in 1:nrow(dat1_test)){
  kramer_S[i,] <- pred_kramer_S(lambda = dat1_test$PoiNb[i], mu = dat1_test$GaSe[i], phi = (summary(ga_reg))$dispersion, rho=kramer_rho, TT = TT, ln=F)
  if (i%%1000==0){print(i)}
}
kramertotalloss <- apply(kramer_S, 2, sum)

for(i in 1:nrow(dat1_test)){
  kramer_S_ln[i,] <- pred_kramer_S(lambda = dat1_test$PoiNb[i], mu = dat1_test$LnSe[i], phi = (summary(ln_reg))$dispersion, rho=kramer_rho_ln, TT = TT,ln=T)
  if (i%%1000==0){print(i)}
}
kramertotalloss_ln <- apply(kramer_S_ln, 2, sum)

hist(kramertotalloss, xaxt="n", xlab = 'total loss of kramer copula model', main = '')
abline(v=actualtotalloss,lwd=4,col="blue")
ecdfkramer <- ecdf(kramertotalloss)
ecdfkramer(actualtotalloss)
(mean(kramertotalloss)-actualtotalloss)/actualtotalloss
kramer_percent<-agg_per(simulated = kramer_S, actual = dat1_test$ClaimAmount)
hist(kramer_percent)

hist(kramertotalloss_ln, xaxt="n", xlab = 'total loss of kramer copula model', main = '')
abline(v=actualtotalloss,lwd=4,col="blue")
ecdfkramer_ln <- ecdf(kramertotalloss_ln)
ecdfkramer_ln(actualtotalloss)
(mean(kramertotalloss_ln)-actualtotalloss)/actualtotalloss
kramer_percent_ln<-agg_per(simulated = kramer_S_ln, actual = dat1_test$ClaimAmount)
hist(kramer_percent_ln)

da$kramer_gamma<-apply(kramer_S,1,mean)
da$kramer_ln<-apply(kramer_S_ln,1,mean)

gini(loss="actual",score=c("ind_ln","cond_ln","kramer_ln","our_ln"),data=da)
gini(loss="actual",score=c("ind_ln","cond_ln","our_ln","kramer_ln","ind_gamma","cond_gamma","our_gamma","kramer_gamma"),data=da)


ks.test(jitter(ind_percent_ln),"punif")
ks.test(jitter(condi_percent_ln),"punif")
ks.test(jitter(kramer_percent_ln),"punif")
ks.test(jitter(our_percent_ln),"punif")
```

```{r}
ifm_rho_kramer_nb <- function(ClaimNb, lambda, sigma, Sev, mu, 
                           phi, ln){
  
  alpha = 1/phi # shape parameter of gamma distribution
  beta = alpha/mu # rate parameter of gamma distribution
  
  # calculate u, v, w from Kramer(2013)
  if (ln==F) {
    u = pgamma(q = Sev, shape = ClaimNb*alpha, rate = ClaimNb*beta)
  }
  if (ln==T){
    u = pnorm(q = Sev, mean = mu, sd = sqrt(phi) )
  }
  v = pNBItr(q = ClaimNb, mu=lambda, sigma = sigma)#pPOtr(q = ClaimNb, mu=lambda)
  w = pNBItr(q = ClaimNb-1, mu=lambda, sigma = sigma)#pPOtr(q = ClaimNb - 1, mu=lambda)
  
  #minus joint log-likelihood
  object_fun <- function(rho){
    -sum(log(D1(u, v, rho)-D1(u, w, rho)))
  }
  
  ifm_joint <- optim(par=0,
                     fn = object_fun,
                     lower=-1,
                     upper=1,
                     method = 'Brent')
  # rho_hat = (exp(2*ifm_joint$par)-1)/(exp(2*ifm_joint$par)+1)
  rho_hat = ifm_joint$par
  return(rho_hat)
}

(kramer_rho_ln_nb <-ifm_rho_kramer_nb(
  ClaimNb = dat2_learn$ClaimNb,
  lambda = dat2_learn$NBNb,
  sigma = 1/nb_reg$theta,
  Sev = dat2_learn$LnSev,
  mu = dat2_learn$LnSe, # mean of gamma distribution
  phi = (summary(ln_reg))$dispersion, # dispersion parameter of gamma distribution
  ln=T))
```

```{r}
pred_kramer_S_nb <- function(lambda, sigma, mu, phi, rho, TT,ln){
  S <- rep(0,TT)
  alpha = 1/phi # shape parameter of gamma distribution
  beta = 1/(phi*mu) # rate parameter of gamma distribution
  for(i in 1:TT){
    if (ln==F){
      sev <- rgamma(1,shape = alpha, rate = beta)
      u = pgamma(q = sev, shape = alpha, rate = beta)
    }
    if (ln==T){
      sev <- exp(rnorm(1, mean = mu, sd = sqrt(phi)) )
      u = pnorm(q = log(sev), mean = mu, sd = sqrt(phi) )
    }
    Pr_N<-rep(NA,4)
    Pr_N[0+1] <- pNBI(0, mu = lambda, sigma = sigma)#ppois(0, lambda)
    for (k in 1:2){
      v = pNBItr(q=k, mu=lambda, sigma=sigma)#pPOtr(q = k, mu=lambda)
      w = pNBItr(q=k-1, mu=lambda, sigma=sigma)#pPOtr(q = k-1, mu=lambda)
      Pr_N[k+1] <- (D1(u,v,rho)-D1(u,w,rho))*(1-Pr_N[0+1])
    }
    Pr_N[4]<-1-sum(Pr_N[1:3])
    R=which(as.vector(rmultinom(1,1,prob=Pr_N))==1)-1
    S[i]=R*sev
    if (is.na(S[i])==1) stop("NA generated") 
    }
 return(S)
}

pred_condition_S_nb <- function(lambda, sigma, mu, phi, coef_N, TT, dis){
  S <- rep(0,TT)
  for(i in 1:TT){
    N <- rNBI(1, mu=lambda, sigma = sigma)#rpois(1, lambda)
    if (N == 0){
      S[i] = 0
    } 
    else{
      if (dis=="gamma"){
        mu1 = mu * exp(N*coef_N)
        alpha = 1/phi # shape parameter of gamma distribution
        beta = 1/(phi*mu1) # rate parameter of gamma distribution
        S[i] <- N*rgamma(1, shape = N*alpha, rate = N*beta)
      }
      if (dis=="lnorm"){
        mu1 = mu + N*coef_N
        S[i] <- N*exp(rnorm(1, mean = mu1, sd = sqrt(phi)))
      }
      if (dis=="lgamma"){
        mu1 = mu + N*coef_N
        alpha = 1/phi
        beta = 1/(phi*mu1)
        S[i] <- N*exp(rgamma(1, shape = alpha, rate=beta))
      }
    }
  }
  return(S)
}
```

```{r}
independent_S_ln_nb = matrix(nrow = nrow(dat1_test), ncol = TT)
for(i in 1:nrow(dat1_test)){
  independent_S_ln_nb[i,] <- pred_condition_S_nb(lambda = dat1_test$NBNb[i], sigma = 1/nb_reg$theta, mu = dat1_test$LnSe[i], phi = (summary(ln_reg))$dispersion, coef_N = 0, TT = TT, dis="lnorm")
    if (i%%1000==0){print(i)}
}
independenttotalloss_ln_nb <- apply(independent_S_ln_nb, 2, sum)
da$ind_ln_nb <-apply(independent_S_ln,1,mean)

condition_S_ln_nb = matrix(nrow = nrow(dat1_test), ncol = TT)
for(i in 1:nrow(dat1_test)){
  condition_S_ln_nb[i,] <- pred_condition_S_nb(lambda = dat1_test$NBNb[i], sigma = 1/nb_reg$theta, mu = dat1_test$LnSe_NN[i], phi = summary(ln_reg_n)$dispersion, coef_N=coef_N_ln, TT = TT, dis="lnorm")
  if (i%%1000==0){print(i)}
}
conditiontotalloss_ln_nb <- apply(condition_S_ln_nb, 2, sum)
da$cond_ln_nb <-apply(condition_S_ln_nb, 1,mean)

kramer_S_ln_nb = matrix(nrow = nrow(dat1_test), ncol = TT)
for(i in 1:nrow(dat1_test)){
  kramer_S_ln_nb[i,] <- pred_kramer_S_nb(lambda = dat1_test$NBNb[i], sigma = 1/nb_reg$theta, 
                  mu = dat1_test$LnSe[i], phi = (summary(ln_reg))$dispersion, rho=kramer_rho_ln_nb, TT = TT,ln=T)
  if (i%%1000==0){print(i)}
}
kramertotalloss_ln_nb <- apply(kramer_S_ln_nb, 2, sum)
da$kramer_ln_nb<-apply(kramer_S_ln_nb,1,mean)

gini(loss="actual",score=c("ind_ln","cond_ln","kramer_ln","our_ln","ind_ln_nb","cond_ln_nb","kramer_ln_nb"),data=da)
```

```{r}
pred_S_m <- function(lambda_1, lambda_2, pi_1, pi_2, mu, phi, rho_hat, TT, dis){
  S <- rep(0, TT) ## aggregated claims amount
  for(i in 1:TT){
    I <- rbinom(1, 1, pi_2)
    if(I == 1){
      lambda = lambda_2
    }
    else{
      lambda = lambda_1
    }
    T_1 = rexp(1, lambda)
    if(T_1 > 1){
      S[i] = 0
    }
    else{
      z = mvrnorm(n=1, c(0,0), matrix(c(1, rho_hat, rho_hat, 1), 2, 2))# Generate  $(z_{i,1},z_{i,2})$ from the bivariate normal distribution with correlation $\hat{\rho}$
      t = inverse_cdf_T(pnorm(z[1]), lambda = lambda)# Recover $T_{n+1}$ by inverting its distribution function
      N = 1
      while(t <= 1){
        N = N + 1
        t = t + rexp(1, lambda)
      }
      # if (t<=1) {N=2}
      # if (t>1) {N=1}
      if (dis=="gamma"){
         alpha = 1/phi # shape parameter of gamma distribution
         beta = 1/(phi*mu) # rate parameter of gamma distribution
         S[i] = N*qgamma(pnorm(z[2]), shape = alpha*N, rate = beta*N)
        }
      if (dis=="lnorm"){
          S[i] = N*exp(qnorm(pnorm(z[2]), mean=mu, sd=sqrt(phi) ) )
      }
      if (dis=="lgamma"){
        alpha = 1/phi # shape parameter of gamma distribution
        beta = 1/(phi*mu) # rate parameter of gamma distribution
        S[i] = N*exp(qgamma(pnorm(z[2]), shape=alpha, rate=beta ) )
      }
      }
    }
  return(S)
}
```

```{r}
our_S_ln_m = matrix(nrow = nrow(dat1_test), ncol = TT)
for(i in 1:nrow(dat1_test)){
  our_S_ln_m[i,] <- pred_S_m(lambda_1 = dat1_test$MXNb_1[i],
                             lambda_2 = dat1_test$MXNb_2[i],
                             pi_1 = mx_reg$prob[1],
                             pi_2 = mx_reg$prob[2],
                             mu = dat1_test$LnSe[i], phi = (summary(ln_reg))$dispersion, rho_hat=rho_hat_ln_m, TT = TT, dis="lnorm")
  if (i%%1000==0){print(i)}
}
ourtotalloss_ln_m <- apply(our_S_ln_m, 2, sum)
da$our_ln_m<-apply(our_S_ln_m,1,mean)

gini(loss="actual",score=c("ind_ln","cond_ln","kramer_ln","our_ln","ind_ln_nb","cond_ln_nb","kramer_ln_nb","our_ln_m"),data=da)
```

```{r}
gini(loss="actual",score=c("ind_ln_nb","cond_ln_nb","kramer_ln_nb","our_ln_m"),data=da)
```

```{r}
ecdfindependent_ln_nb <- ecdf(independenttotalloss_ln_nb)
ecdfindependent_ln_nb(actualtotalloss)
(mean(independenttotalloss_ln_nb)-actualtotalloss)/actualtotalloss
ind_percent_ln_nb<-agg_per(simulated = independent_S_ln_nb, actual = dat1_test$ClaimAmount)

ecdfcondition_ln_nb <- ecdf(conditiontotalloss_ln_nb)
ecdfcondition_ln_nb(actualtotalloss)
(mean(conditiontotalloss_ln_nb)-actualtotalloss)/actualtotalloss
condi_percent_ln_nb<-agg_per(simulated = condition_S_ln_nb, actual = dat1_test$ClaimAmount)

ecdfkramer_ln_nb <- ecdf(kramertotalloss_ln_nb)
ecdfkramer_ln_nb(actualtotalloss)
(mean(kramertotalloss_ln_nb)-actualtotalloss)/actualtotalloss
kramer_percent_ln_nb<-agg_per(simulated = kramer_S_ln_nb, actual = dat1_test$ClaimAmount)

ecdfour_ln_m <- ecdf(ourtotalloss_ln_m)
ecdfour_ln_m(actualtotalloss)
(mean(ourtotalloss_ln_m)-actualtotalloss)/actualtotalloss
our_percent_ln_m<-agg_per(simulated = our_S_ln_m, actual = dat1_test$ClaimAmount)

ks.test(jitter(ind_percent_ln),"punif")
ks.test(jitter(condi_percent_ln),"punif")
ks.test(jitter(kramer_percent_ln),"punif")
ks.test(jitter(our_percent_ln),"punif")
ks.test(jitter(ind_percent_ln_nb),"punif")
ks.test(jitter(condi_percent_ln_nb),"punif")
ks.test(jitter(kramer_percent_ln_nb),"punif")
ks.test(jitter(our_percent_ln_m),"punif")
```
```{r}
pred_condition_S_m <- function(lambda_1, lambda_2, pi_1, pi_2,mu, phi, coef_N, TT, dis){
  S <- rep(0,TT)
  for(i in 1:TT){
    I <- rbinom(1, 1, pi_2)
    if(I == 1){
      lambda = lambda_2
    }
    else{
      lambda = lambda_1
    }
    N <- rpois(1, lambda)
    if (N == 0){
      S[i] = 0
    } 
    else{
      if (dis=="gamma"){
        mu1 = mu * exp(N*coef_N)
        alpha = 1/phi # shape parameter of gamma distribution
        beta = 1/(phi*mu1) # rate parameter of gamma distribution
        S[i] <- N*rgamma(1, shape = N*alpha, rate = N*beta)
      }
      if (dis=="lnorm"){
        mu1 = mu + N*coef_N
        S[i] <- N*exp(rnorm(1, mean = mu1, sd = sqrt(phi)))
      }
      if (dis=="lgamma"){
        mu1 = mu + N*coef_N
        alpha = 1/phi
        beta = 1/(phi*mu1)
        S[i] <- N*exp(rgamma(1, shape = alpha, rate=beta))
      }
    }
  }
  return(S)
}
```

```{r}
dmtr <- function(y, lambda_1, lambda_2, pi_1, pi_2){
  if(y>=1){
    dp <- (pi_1*dpois(y,lambda_1)+pi_2*dpois(y,lambda_2))/(1-(pi_1*dpois(0,lambda_1)+pi_2*dpois(0,lambda_2)))
  } else {
    dp = 0
  }
  return(dp)
}

pmtr <- function(q, lambda_1, lambda_2, pi_1, pi_2){
  if(q<1){
    cdf <- 0
  } else {
    cdf = 0
    i = 1 
    while(i <=floor(q)){
      cdf <- cdf + dmtr(i,lambda_1, lambda_2, pi_1, pi_2)
      i <- i+1
    }
  }
  return(cdf)
}
```



```{r}
ifm_rho_kramer_m <- function(ClaimNb, lambda_1, lambda_2, pi_1, pi_2, Sev, mu, 
                           phi, ln){
  
  alpha = 1/phi # shape parameter of gamma distribution
  beta = alpha/mu # rate parameter of gamma distribution
  
  # calculate u, v, w from Kramer(2013)
  if (ln==F) {
    u = pgamma(q = Sev, shape = ClaimNb*alpha, rate = ClaimNb*beta)
  }
  if (ln==T){
    u = pnorm(q = Sev, mean = mu, sd = sqrt(phi) )
  }
  v = pmtr(q = ClaimNb, lambda_1, lambda_2, pi_1, pi_2)#pPOtr(q = ClaimNb, mu=lambda)
  w = pmtr(q = ClaimNb-1,lambda_1, lambda_2, pi_1, pi_2)#pPOtr(q = ClaimNb - 1, mu=lambda)
  
  #minus joint log-likelihood
  object_fun <- function(rho){
    -sum(log(D1(u, v, rho)-D1(u, w, rho)))
  }
  
  ifm_joint <- optim(par=0,
                     fn = object_fun,
                     lower=-1,
                     upper=1,
                     method = 'Brent')
  # rho_hat = (exp(2*ifm_joint$par)-1)/(exp(2*ifm_joint$par)+1)
  rho_hat = ifm_joint$par
  return(rho_hat)
}

(kramer_rho_ln_m <-ifm_rho_kramer_m(
  ClaimNb = as.numeric(dat2_learn$ClaimNb),
  lambda_1 = dat2_learn$MXNb_1,
  lambda_2 = dat2_learn$MXNb_2,
  pi_1 = mx_reg$prob[1],
  pi_2 = mx_reg$prob[2],
  Sev = dat2_learn$LnSev,
  mu = dat2_learn$LnSe, # mean of gamma distribution
  phi = (summary(ln_reg))$dispersion, # dispersion parameter of gamma distribution
  ln=T))
```
```{r}
pred_kramer_S_m <- function(lambda_1, lambda_2, pi_1, pi_2, mu, phi, rho, TT,ln){
  S <- rep(0,TT)
  alpha = 1/phi # shape parameter of gamma distribution
  beta = 1/(phi*mu) # rate parameter of gamma distribution
  for(i in 1:TT){
    if (ln==F){
      sev <- rgamma(1,shape = alpha, rate = beta)
      u = pgamma(q = sev, shape = alpha, rate = beta)
    }
    if (ln==T){
      sev <- exp(rnorm(1, mean = mu, sd = sqrt(phi)) )
      u = pnorm(q = log(sev), mean = mu, sd = sqrt(phi) )
    }
    Pr_N<-rep(NA,4)
    Pr_N[0+1] <- pMX(0, mu = list(mu1 = lambda_1, mu2 = lambda_2), 
                     pi = list(pi1 = pi_1, pi2 = pi_2), family = list(fam1 = "PO", fam2 = "PO"))
    #ppois(0, lambda)
    for (k in 1:2){
      v = pmtr(q=k, lambda_1, lambda_2, pi_1, pi_2)#pPOtr(q = k, mu=lambda)
      w = pmtr(q=k-1, lambda_1, lambda_2, pi_1, pi_2)#pPOtr(q = k-1, mu=lambda)
      Pr_N[k+1] <- (D1(u,v,rho)-D1(u,w,rho))*(1-Pr_N[0+1])
    }
    Pr_N[4]<-1-sum(Pr_N[1:3])
    R=which(as.vector(rmultinom(1,1,prob=Pr_N))==1)-1
    S[i]=R*sev
    if (is.na(S[i])==1) stop("NA generated") 
    }
 return(S)
}
```

```{r}
independent_S_ln_m = matrix(nrow = nrow(dat1_test), ncol = TT)
for(i in 1:nrow(dat1_test)){
  independent_S_ln_m[i,] <- pred_condition_S_m(lambda_1 = dat1_test$MXNb_1[i],
                             lambda_2 = dat1_test$MXNb_2[i],
                             pi_1 = mx_reg$prob[1],
                             pi_2 = mx_reg$prob[2], mu = dat1_test$LnSe[i], phi = (summary(ln_reg))$dispersion, coef_N = 0, TT = TT, dis="lnorm")
    if (i%%1000==0){print(i)}
}
independenttotalloss_ln_m <- apply(independent_S_ln_m, 2, sum)
da$ind_ln_m <-apply(independent_S_ln_m,1,mean)

condition_S_ln_m = matrix(nrow = nrow(dat1_test), ncol = TT)
for(i in 1:nrow(dat1_test)){
  condition_S_ln_m[i,] <- pred_condition_S_m(lambda_1 = dat1_test$MXNb_1[i],
                             lambda_2 = dat1_test$MXNb_2[i],
                             pi_1 = mx_reg$prob[1],
                             pi_2 = mx_reg$prob[2], mu = dat1_test$LnSe[i], phi = (summary(ln_reg))$dispersion, coef_N = 0, TT = TT, dis="lnorm")
  if (i%%1000==0){print(i)}
}
conditiontotalloss_ln_m <- apply(condition_S_ln_m, 2, sum)
da$cond_ln_m <-apply(condition_S_ln_m, 1,mean)

kramer_S_ln_m = matrix(nrow = nrow(dat1_test), ncol = TT)
for(i in 1:nrow(dat1_test)){
  kramer_S_ln_m[i,] <- pred_kramer_S_m(lambda_1 = dat1_test$MXNb_1[i],
                             lambda_2 = dat1_test$MXNb_2[i],
                             pi_1 = mx_reg$prob[1],
                             pi_2 = mx_reg$prob[2], mu = dat1_test$LnSe[i],phi = (summary(ln_reg))$dispersion, rho=kramer_rho_ln_m, TT = TT,ln=T)
  if (i%%1000==0){print(i)}
}
kramertotalloss_ln_m <- apply(kramer_S_ln_m, 2, sum)
da$kramer_ln_m<-apply(kramer_S_ln_m,1,mean)
```

```{r}
gini(loss="actual",score=c("ind_ln","cond_ln","kramer_ln","our_ln","ind_ln_nb","cond_ln_nb","kramer_ln_nb","ind_ln_m","cond_ln_m","kramer_ln_m"),data=da)
```
```{r}
claim_frequency <- data.frame(actual=dat1_test$ClaimNb,poi=dat1_test$PoiNb,nb=dat1_test$NBNb,mixpoi=dat1_test$MXNb)
gini(loss="actual",score=c("poi","nb","mixpoi"),data=claim_frequency)
```
```{r}
ecdfindependent_ln_m <- ecdf(independenttotalloss_ln_m)
ecdfindependent_ln_m(actualtotalloss)
(mean(independenttotalloss_ln_m)-actualtotalloss)/actualtotalloss
ind_percent_ln_m<-agg_per(simulated = independent_S_ln_m, actual = dat1_test$ClaimAmount)

ecdfcondition_ln_m <- ecdf(conditiontotalloss_ln_m)
ecdfcondition_ln_m(actualtotalloss)
(mean(conditiontotalloss_ln_m)-actualtotalloss)/actualtotalloss
condi_percent_ln_m<-agg_per(simulated = condition_S_ln_m, actual = dat1_test$ClaimAmount)

ecdfkramer_ln_m <- ecdf(kramertotalloss_ln_m)
ecdfkramer_ln_m(actualtotalloss)
(mean(kramertotalloss_ln_m)-actualtotalloss)/actualtotalloss
kramer_percent_ln_m<-agg_per(simulated = kramer_S_ln_m, actual = dat1_test$ClaimAmount)

ks.test(jitter(ind_percent_ln),"punif")
ks.test(jitter(condi_percent_ln),"punif")
ks.test(jitter(kramer_percent_ln),"punif")
ks.test(jitter(our_percent_ln),"punif")
ks.test(jitter(ind_percent_ln_nb),"punif")
ks.test(jitter(condi_percent_ln_nb),"punif")
ks.test(jitter(kramer_percent_ln_nb),"punif")
ks.test(jitter(ind_percent_ln_m),"punif")
ks.test(jitter(condi_percent_ln_m),"punif")
ks.test(jitter(kramer_percent_ln_m),"punif")
ks.test(jitter(our_percent_ln_m),"punif")
```


```{r}
dm <- function(y, lambda_1, lambda_2, pi_1, pi_2){
  dp <- (pi_1*dpois(y,lambda_1)+pi_2*dpois(y,lambda_2))/(1-(pi_1*dpois(0,lambda_1)+pi_2*dpois(0,lambda_2)))
  return(dp)
}
numrow = 5
expnb<-rep(0,numrow)
for(i in 1:numrow){
  expnb[i]<-sum(dnbinom(i-1,mu=dat1_test$NBNb,size=summary(nb_reg)$theta)) }
expp      <- rep(0,numrow)
for(i in 1:numrow){
  expp[i] <- sum(dpois((i-1),dat1_test$PoiNb)) }
expmp      <- rep(0,numrow)
for(i in 1:numrow){
  expmp[i] <- sum(dm((i-1),dat1_test$MXNb_1,dat1_test$MXNb_2, mx_reg$prob[1], mx_reg$prob[2])) }
emp  <-rep(0,numrow)
for(i in 1:numrow){
  emp[i]<-sum(dat1_test$ClaimNb==(i-1))
}
freqtable <- cbind(emp, expp, expmp, expnb)
freqtable <- rbind(freqtable, colSums((freqtable - cbind(emp, emp, emp, emp))^2/freqtable))
```






```{r}
gini(loss="actual",score=c("ind_ln","cond_ln","kramer_ln","our_ln","ind_ln_nb","cond_ln_nb","kramer_ln_nb","tweedie"),data=da)
```

```{r}
gini(loss='ClaimNb',score=c('PoiNb','NBNb','MXNb'),dat=dat1_test)
```

```{r}
ifm_rho_t <- function(ClaimSev, ClaimNb, lambda, mu, phi, sev.family, nu){
           u_1 = (1-dpois(0,lambda)-dpois(1,lambda))/(1-dpois(0,lambda))#the $Pr(N^*=2+)$
           z_1 = qt(u_1, df = nu) 
           switch (sev.family ,
                   "gamma"= {u_2 = pgamma(q = ClaimSev, shape = ClaimNb/phi, rate = ClaimNb/(phi*mu))},
                   "lnorm"= {u_2 = plnorm(q = ClaimSev, meanlog=mu, sdlog = phi)},
                   stop("Wrong 'sev.family'")
           )
           z_2 = qt(u_2, df = nu) 
           obj_fun <- function(g_rho){
             rho = (exp(2*g_rho)-1)/(exp(2*g_rho)+1)
             ind_1 = ifelse(ClaimNb==1, 1, 0)
             ind_2 = ifelse(ClaimNb==2, 1, 0)
             logp_1 = pt(q = -(z_1-rho*z_2)/sqrt((1-rho^2)*(nu+z_2^2)/(nu+1)), df = nu+1, log.p = TRUE)
             logp_2 = pt(q = (z_1-rho*z_2)/sqrt((1-rho^2)*(nu+z_2^2)/(nu+1)), df = nu+1, log.p = TRUE)
             obj_value = -sum(ind_1*logp_1+ind_2*logp_2)
             return(obj_value)
           }
           g_rho = (optim(par=0.2, obj_fun, method='BFGS'))$par
           rho = (exp(2*g_rho)-1)/(exp(2*g_rho)+1)
           return(rho)
}
```


```{r}
(rho_hat_t_10 = ifm_rho_t(ClaimSev = dat2$ClaimSev[dat2$ind!=ind_test],
          ClaimNb = dat2$ClaimNb[dat2$ind!=ind_test],
          lambda = dat2$PoiNb[dat2$ind!=ind_test],
          mu = dat2$LnSe[dat2$ind!=ind_test],
          phi = (summary(ln_reg))$dispersion,
          sev.family = 'lnorm',
          nu = 10))

(rho_hat_t_15 = ifm_rho_t(ClaimSev = dat2$ClaimSev[dat2$ind!=ind_test],
          ClaimNb = dat2$ClaimNb[dat2$ind!=ind_test],
          lambda = dat2$PoiNb[dat2$ind!=ind_test],
          mu = dat2$LnSe[dat2$ind!=ind_test],
          phi = (summary(ln_reg))$dispersion,
          sev.family = 'lnorm',
          nu = 15))

(rho_hat_t_20 = ifm_rho_t(ClaimSev = dat2$ClaimSev[dat2$ind!=ind_test],
          ClaimNb = dat2$ClaimNb[dat2$ind!=ind_test],
          lambda = dat2$PoiNb[dat2$ind!=ind_test],
          mu = dat2$LnSe[dat2$ind!=ind_test],
          phi = (summary(ln_reg))$dispersion,
          sev.family = 'lnorm',
          nu = 20))
```


```{r}
pred_S_t <- function(lambda, mu, phi, rho_hat, TT, dis, nu){
  S <- rep(0, TT) ## aggregated claims amount
  for(i in 1:TT){
    T_1 = rexp(1, lambda)
    if(T_1 > 1){
      S[i] = 0
    }
    else{
      z = rStudent(n=1, df = nu, c(0,0), matrix(c(1, rho_hat, rho_hat, 1), 2, 2))# Generate  $(z_{i,1},z_{i,2})$ from the bivariate t distribution with correlation $\hat{\rho}$
      t = inverse_cdf_T(pt(z[1], df = nu), lambda = lambda)# Recover $T_{n+1}$ by inverting its distribution function
      N = 1
      while(t <= 1){
        N = N + 1
        t = t + rexp(1, lambda)
      }
      # if (t<=1) {N=2}
      # if (t>1) {N=1}
      if (dis=="gamma"){
         alpha = 1/phi # shape parameter of gamma distribution
         beta = 1/(phi*mu) # rate parameter of gamma distribution
         S[i] = N*qgamma(pt(z[2], df = nu), shape = alpha*N, rate = beta*N)
        }
      if (dis=="lnorm"){
          S[i] = N*exp(qnorm(pt(z[2], df = nu), mean=mu, sd=sqrt(phi) ) )
      }
      if (dis=="lgamma"){
        alpha = 1/phi # shape parameter of gamma distribution
        beta = 1/(phi*mu) # rate parameter of gamma distribution
        S[i] = N*exp(qgamma(pt(z[2], df = nu), shape=alpha, rate=beta ) )
      }
      }
    }
  return(S)
}
```

```{r}
library(nvmix)
our_S_t_ln <- matrix(nrow = sum(dat1$ind==ind_test), ncol = TT)
for(i in 1:nrow(dat1_test)){
  our_S_t_ln[i,] <- pred_S_t(lambda = dat1_test$PoiNb[i], mu = dat1_test$LnSe[i], phi = (summary(ln_reg))$dispersion, rho_hat=rho_hat_t_10, TT = TT, dis="lnorm", nu =10)
  if (i%%1000==0){print(i)}
}
#ourtotalloss_ln_t <- apply(our_S_t_ln, 2, sum)
#hist(ourtotalloss_ln_t, xaxt="n", xlab = 'total loss of t copula model', main = '')
#abline(v=actualtotalloss,lwd=4,col="blue")
da$our_ln_t_10<-apply(our_S_t_ln,1,mean)

our_S_t_ln <- matrix(nrow = sum(dat1$ind==ind_test), ncol = TT)
for(i in 1:nrow(dat1_test)){
  our_S_t_ln[i,] <- pred_S_t(lambda = dat1_test$PoiNb[i], mu = dat1_test$LnSe[i], phi = (summary(ln_reg))$dispersion, rho_hat=rho_hat_t_15, TT = TT, dis="lnorm", nu =15)
  if (i%%1000==0){print(i)}
}
da$our_ln_t_15<-apply(our_S_t_ln,1,mean)

our_S_t_ln <- matrix(nrow = sum(dat1$ind==ind_test), ncol = TT)
for(i in 1:nrow(dat1_test)){
  our_S_t_ln[i,] <- pred_S_t(lambda = dat1_test$PoiNb[i], mu = dat1_test$LnSe[i], phi = (summary(ln_reg))$dispersion, rho_hat=rho_hat_t_20, TT = TT, dis="lnorm", nu =20)
  if (i%%1000==0){print(i)}
}
da$our_ln_t_20<-apply(our_S_t_ln,1,mean)
```

```{r}
gini(loss="actual",score=c("our_ln_t_10","our_ln_t_15","our_ln_t_20"),data=da)
gini(loss="actual",score=c("our_ln_t_10","our_ln_t_15","our_ln_t_20","our_ln"),data=da)
```
```{r}
rho_hat_t_10
rho_hat_t_15
rho_hat_t_20
rho_hat_ln
```

```{r}
kendalls_tau <- function(rho) (2/pi)*asin(rho)
kendalls_tau(rho_hat_t_10)
kendalls_tau(rho_hat_t_15)
kendalls_tau(rho_hat_t_20)
kendalls_tau(rho_hat_ln)
```
```{r}
tail_depend <- function(nu, rho) 2*pt(q = -sqrt((nu+1)*(1-rho)/(1+rho)), df =nu+1)
tail_depend(10, rho = rho_hat_t_10)
tail_depend(15, rho = rho_hat_t_15)
tail_depend(20, rho = rho_hat_t_20)
```


